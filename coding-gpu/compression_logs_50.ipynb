{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compression logs order-50 markov chain\n",
    "\n",
    "Compression\n",
    "```bash\n",
    "bash compress.sh Simulated-data-main/50-order_markov_chain.txt output/50_hmm.dzip com MODEL_PATH\n",
    "```\n",
    "\n",
    "Decompress\n",
    "```bash\n",
    "bash decompress.sh output/50_hmm.dzip output/decom_hmm50 com MODEL_PATH\n",
    "```\n",
    "\n",
    "Verify successful decompression\n",
    "```bash\n",
    "bash compare.sh Simulated-data-main/50-order_markov_chain.txt output/decom_hmm50\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compression Logs\n",
    "\n",
    "```bash\n",
    "Seq Length 199999\n",
    "Using cuda\n",
    "Vocab Size 3\n",
    "CudNN version 90100\n",
    "/home/jx1421/Dzip-torch/torch_venv/lib64/python3.9/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
    "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
    "/home/jx1421/Dzip-torch/torch_venv/lib64/python3.9/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
    "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
    "/home/jx1421/Dzip-torch/torch_venv/lib64/python3.9/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
    "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
    "/home/jx1421/Dzip-torch/torch_venv/lib64/python3.9/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
    "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
    "0.29633545875549316 secs\n",
    "====> Epoch: 1 Average loss: 0.6145929215.7759\n",
    "Loss went from 100000000.0000 to 0.6146\n",
    "/home/jx1421/Dzip-torch/torch_venv/lib64/python3.9/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
    "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
    "/home/jx1421/Dzip-torch/torch_venv/lib64/python3.9/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
    "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
    "/home/jx1421/Dzip-torch/torch_venv/lib64/python3.9/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
    "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
    "/home/jx1421/Dzip-torch/torch_venv/lib64/python3.9/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
    "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
    "0.10050129890441895 secs\n",
    "====> Epoch: 2 Average loss: 0.5010584940.5041\n",
    "Loss went from 0.6146 to 0.5011\n",
    "/home/jx1421/Dzip-torch/torch_venv/lib64/python3.9/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
    "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
    "/home/jx1421/Dzip-torch/torch_venv/lib64/python3.9/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
    "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
    "/home/jx1421/Dzip-torch/torch_venv/lib64/python3.9/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
    "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
    "/home/jx1421/Dzip-torch/torch_venv/lib64/python3.9/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
    "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
    "0.0991973876953125 secs\n",
    "====> Epoch: 3 Average loss: 0.5014350258.4910\n",
    "/home/jx1421/Dzip-torch/torch_venv/lib64/python3.9/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
    "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
    "/home/jx1421/Dzip-torch/torch_venv/lib64/python3.9/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
    "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
    "/home/jx1421/Dzip-torch/torch_venv/lib64/python3.9/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
    "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
    "/home/jx1421/Dzip-torch/torch_venv/lib64/python3.9/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
    "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
    "0.1001577377319336 secs\n",
    "====> Epoch: 4 Average loss: 0.5010130510.5001\n",
    "Loss went from 0.5011 to 0.5010\n",
    "/home/jx1421/Dzip-torch/torch_venv/lib64/python3.9/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
    "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
    "/home/jx1421/Dzip-torch/torch_venv/lib64/python3.9/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
    "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
    "/home/jx1421/Dzip-torch/torch_venv/lib64/python3.9/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
    "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
    "/home/jx1421/Dzip-torch/torch_venv/lib64/python3.9/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
    "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
    "0.09946775436401367 secs\n",
    "====> Epoch: 5 Average loss: 0.5006538789.4888\n",
    "Loss went from 0.5010 to 0.5007\n",
    "/home/jx1421/Dzip-torch/torch_venv/lib64/python3.9/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
    "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
    "/home/jx1421/Dzip-torch/torch_venv/lib64/python3.9/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
    "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
    "/home/jx1421/Dzip-torch/torch_venv/lib64/python3.9/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
    "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
    "/home/jx1421/Dzip-torch/torch_venv/lib64/python3.9/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
    "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
    "0.09856748580932617 secs\n",
    "====> Epoch: 6 Average loss: 0.5005717078.4932\n",
    "Loss went from 0.5007 to 0.5006\n",
    "/home/jx1421/Dzip-torch/torch_venv/lib64/python3.9/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
    "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
    "/home/jx1421/Dzip-torch/torch_venv/lib64/python3.9/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
    "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
    "/home/jx1421/Dzip-torch/torch_venv/lib64/python3.9/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
    "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
    "/home/jx1421/Dzip-torch/torch_venv/lib64/python3.9/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
    "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
    "0.09808850288391113 secs\n",
    "====> Epoch: 7 Average loss: 0.5010967236.4862\n",
    "/home/jx1421/Dzip-torch/torch_venv/lib64/python3.9/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
    "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
    "/home/jx1421/Dzip-torch/torch_venv/lib64/python3.9/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
    "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
    "/home/jx1421/Dzip-torch/torch_venv/lib64/python3.9/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
    "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
    "/home/jx1421/Dzip-torch/torch_venv/lib64/python3.9/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
    "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
    "0.10256075859069824 secs\n",
    "====> Epoch: 8 Average loss: 0.5006354227.4883\n",
    "Done\n",
    "Using MODEL_PATH for encoding\n",
    "array type int64\n",
    "/home/jx1421/Dzip-torch/torch_venv/lib64/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
    "  warnings.warn(\n",
    "3124\n",
    "0.4248666763305664 secs\n",
    "Iter 100 Loss 0.5446 Moving Loss 0.5446 Train Loss 0.8989\n",
    "0.18551230430603027 secs\n",
    "Iter 200 Loss 0.5255 Moving Loss 0.5064 Train Loss 0.5536\n",
    "0.17279577255249023 secs\n",
    "Iter 300 Loss 0.5197 Moving Loss 0.5079 Train Loss 0.5443\n",
    "0.1715404987335205 secs\n",
    "Iter 400 Loss 0.5157 Moving Loss 0.5040 Train Loss 0.5209\n",
    "0.17111420631408691 secs\n",
    "Iter 500 Loss 0.5139 Moving Loss 0.5068 Train Loss 0.5172\n",
    "0.17092347145080566 secs\n",
    "Iter 600 Loss 0.5126 Moving Loss 0.5060 Train Loss 0.5405\n",
    "0.17201590538024902 secs\n",
    "Iter 700 Loss 0.5111 Moving Loss 0.5019 Train Loss 0.5059\n",
    "0.17281341552734375 secs\n",
    "Iter 800 Loss 0.5099 Moving Loss 0.5016 Train Loss 0.5142\n",
    "0.17194890975952148 secs\n",
    "Iter 900 Loss 0.5088 Moving Loss 0.4999 Train Loss 0.5030\n",
    "0.17166614532470703 secs\n",
    "Iter 1000 Loss 0.5081 Moving Loss 0.5021 Train Loss 0.5044\n",
    "0.17149901390075684 secs\n",
    "Iter 1100 Loss 0.5076 Moving Loss 0.5019 Train Loss 0.5148\n",
    "0.1712808609008789 secs\n",
    "Iter 1200 Loss 0.5070 Moving Loss 0.5004 Train Loss 0.5046\n",
    "0.1721174716949463 secs\n",
    "Iter 1300 Loss 0.5068 Moving Loss 0.5049 Train Loss 0.5081\n",
    "0.17937493324279785 secs\n",
    "Iter 1400 Loss 0.5065 Moving Loss 0.5018 Train Loss 0.5139\n",
    "0.17210125923156738 secs\n",
    "Iter 1500 Loss 0.5061 Moving Loss 0.5009 Train Loss 0.5134\n",
    "0.17155957221984863 secs\n",
    "Iter 1600 Loss 0.5057 Moving Loss 0.5003 Train Loss 0.5019\n",
    "0.17136502265930176 secs\n",
    "Iter 1700 Loss 0.5055 Moving Loss 0.5019 Train Loss 0.5068\n",
    "0.17386269569396973 secs\n",
    "Iter 1800 Loss 0.5058 Moving Loss 0.5112 Train Loss 0.5406\n",
    "0.17100811004638672 secs\n",
    "Iter 1900 Loss 0.5056 Moving Loss 0.5020 Train Loss 0.5150\n",
    "0.17145252227783203 secs\n",
    "Iter 2000 Loss 0.5054 Moving Loss 0.5014 Train Loss 0.5099\n",
    "0.17176365852355957 secs\n",
    "Iter 2100 Loss 0.5052 Moving Loss 0.5003 Train Loss 0.5020\n",
    "0.17096400260925293 secs\n",
    "Iter 2200 Loss 0.5050 Moving Loss 0.5015 Train Loss 0.5033\n",
    "0.1719367504119873 secs\n",
    "Iter 2300 Loss 0.5048 Moving Loss 0.5003 Train Loss 0.5033\n",
    "0.17692971229553223 secs\n",
    "Iter 2400 Loss 0.5046 Moving Loss 0.5008 Train Loss 0.5019\n",
    "0.17185044288635254 secs\n",
    "Iter 2500 Loss 0.5044 Moving Loss 0.5002 Train Loss 0.5035\n",
    "0.17150115966796875 secs\n",
    "Iter 2600 Loss 0.5043 Moving Loss 0.5004 Train Loss 0.5020\n",
    "0.17178130149841309 secs\n",
    "Iter 2700 Loss 0.5042 Moving Loss 0.5007 Train Loss 0.5008\n",
    "0.17129945755004883 secs\n",
    "Iter 2800 Loss 0.5040 Moving Loss 0.5002 Train Loss 0.5043\n",
    "0.1723794937133789 secs\n",
    "Iter 2900 Loss 0.5040 Moving Loss 0.5025 Train Loss 0.5070\n",
    "0.17491436004638672 secs\n",
    "Iter 3000 Loss 0.5039 Moving Loss 0.5007 Train Loss 0.5035\n",
    "Done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decompression Logs\n",
    "\n",
    "```bash\n",
    "Using MODEL_PATH for decoding\n",
    "Using device cuda\n",
    "/home/jx1421/Dzip-torch/torch_venv/lib64/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
    "  warnings.warn(\n",
    "3124\n",
    "Iter 100 Loss 0.5446 Moving Loss 0.5446\n",
    "0.4135406017303467 secs\n",
    "Iter 200 Loss 0.5255 Moving Loss 0.5064\n",
    "0.1791067123413086 secs\n",
    "Iter 300 Loss 0.5197 Moving Loss 0.5079\n",
    "0.17866253852844238 secs\n",
    "Iter 400 Loss 0.5157 Moving Loss 0.5040\n",
    "0.17821550369262695 secs\n",
    "Iter 500 Loss 0.5139 Moving Loss 0.5068\n",
    "0.1796588897705078 secs\n",
    "Iter 600 Loss 0.5126 Moving Loss 0.5060\n",
    "0.1811811923980713 secs\n",
    "Iter 700 Loss 0.5111 Moving Loss 0.5019\n",
    "0.1823279857635498 secs\n",
    "Iter 800 Loss 0.5099 Moving Loss 0.5016\n",
    "0.1844346523284912 secs\n",
    "Iter 900 Loss 0.5088 Moving Loss 0.4999\n",
    "0.1774585247039795 secs\n",
    "Iter 1000 Loss 0.5081 Moving Loss 0.5021\n",
    "0.17678451538085938 secs\n",
    "Iter 1100 Loss 0.5076 Moving Loss 0.5019\n",
    "0.17660117149353027 secs\n",
    "Iter 1200 Loss 0.5070 Moving Loss 0.5004\n",
    "0.18501925468444824 secs\n",
    "Iter 1300 Loss 0.5068 Moving Loss 0.5049\n",
    "0.17740774154663086 secs\n",
    "Iter 1400 Loss 0.5065 Moving Loss 0.5018\n",
    "0.17822861671447754 secs\n",
    "Iter 1500 Loss 0.5061 Moving Loss 0.5009\n",
    "0.17684483528137207 secs\n",
    "Iter 1600 Loss 0.5057 Moving Loss 0.5003\n",
    "0.17747712135314941 secs\n",
    "Iter 1700 Loss 0.5055 Moving Loss 0.5019\n",
    "0.17827630043029785 secs\n",
    "Iter 1800 Loss 0.5058 Moving Loss 0.5112\n",
    "0.17833328247070312 secs\n",
    "Iter 1900 Loss 0.5056 Moving Loss 0.5020\n",
    "0.17685151100158691 secs\n",
    "Iter 2000 Loss 0.5054 Moving Loss 0.5014\n",
    "0.17854952812194824 secs\n",
    "Iter 2100 Loss 0.5052 Moving Loss 0.5003\n",
    "0.17850708961486816 secs\n",
    "Iter 2200 Loss 0.5050 Moving Loss 0.5015\n",
    "0.1830143928527832 secs\n",
    "Iter 2300 Loss 0.5048 Moving Loss 0.5003\n",
    "0.17672324180603027 secs\n",
    "Iter 2400 Loss 0.5046 Moving Loss 0.5008\n",
    "0.17699122428894043 secs\n",
    "Iter 2500 Loss 0.5044 Moving Loss 0.5002\n",
    "0.17689204216003418 secs\n",
    "Iter 2600 Loss 0.5043 Moving Loss 0.5004\n",
    "0.1764833927154541 secs\n",
    "Iter 2700 Loss 0.5042 Moving Loss 0.5007\n",
    "0.17661428451538086 secs\n",
    "Iter 2800 Loss 0.5040 Moving Loss 0.5002\n",
    "0.1779005527496338 secs\n",
    "Iter 2900 Loss 0.5040 Moving Loss 0.5025\n",
    "0.1771411895751953 secs\n",
    "Iter 3000 Loss 0.5039 Moving Loss 0.5007\n",
    "0.17728114128112793 secs\n",
    "Done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison Logs\n",
    "\n",
    "```bash\n",
    "The file \"Simulated-data-main/50-order_markov_chain.txt\" is the same as \"output/decom_hmm50\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
